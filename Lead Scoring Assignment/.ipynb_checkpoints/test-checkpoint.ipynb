{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# To Scale our data\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the max display columns to None so that pandas doesn't sandwich the output \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Leads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospect ID</th>\n",
       "      <th>Lead Number</th>\n",
       "      <th>Lead Origin</th>\n",
       "      <th>Lead Source</th>\n",
       "      <th>Do Not Email</th>\n",
       "      <th>Do Not Call</th>\n",
       "      <th>Converted</th>\n",
       "      <th>TotalVisits</th>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <th>Page Views Per Visit</th>\n",
       "      <th>Last Activity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Specialization</th>\n",
       "      <th>How did you hear about X Education</th>\n",
       "      <th>What is your current occupation</th>\n",
       "      <th>What matters most to you in choosing a course</th>\n",
       "      <th>Search</th>\n",
       "      <th>Magazine</th>\n",
       "      <th>Newspaper Article</th>\n",
       "      <th>X Education Forums</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Digital Advertisement</th>\n",
       "      <th>Through Recommendations</th>\n",
       "      <th>Receive More Updates About Our Courses</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Lead Quality</th>\n",
       "      <th>Update me on Supply Chain Content</th>\n",
       "      <th>Get updates on DM Content</th>\n",
       "      <th>Lead Profile</th>\n",
       "      <th>City</th>\n",
       "      <th>Asymmetrique Activity Index</th>\n",
       "      <th>Asymmetrique Profile Index</th>\n",
       "      <th>Asymmetrique Activity Score</th>\n",
       "      <th>Asymmetrique Profile Score</th>\n",
       "      <th>I agree to pay the amount through cheque</th>\n",
       "      <th>A free copy of Mastering The Interview</th>\n",
       "      <th>Last Notable Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7927b2df-8bba-4d29-b9a2-b6e0beafe620</td>\n",
       "      <td>660737</td>\n",
       "      <td>API</td>\n",
       "      <td>Olark Chat</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Page Visited on Website</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Better Career Prospects</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Interested in other courses</td>\n",
       "      <td>Low in Relevance</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a272436-5132-4136-86fa-dcc88c88f482</td>\n",
       "      <td>660728</td>\n",
       "      <td>API</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>674</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Email Opened</td>\n",
       "      <td>India</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Better Career Prospects</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ringing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Email Opened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8cc8c611-a219-4f35-ad23-fdfd2656bd8a</td>\n",
       "      <td>660727</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Direct Traffic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1532</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Email Opened</td>\n",
       "      <td>India</td>\n",
       "      <td>Business Administration</td>\n",
       "      <td>Select</td>\n",
       "      <td>Student</td>\n",
       "      <td>Better Career Prospects</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Will revert after reading the email</td>\n",
       "      <td>Might be</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Potential Lead</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Email Opened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0cc2df48-7cf4-4e39-9de9-19797f9b38cc</td>\n",
       "      <td>660719</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Direct Traffic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unreachable</td>\n",
       "      <td>India</td>\n",
       "      <td>Media and Advertising</td>\n",
       "      <td>Word Of Mouth</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Better Career Prospects</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ringing</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3256f628-e534-4826-9d63-4a8b88782852</td>\n",
       "      <td>660681</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Google</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Converted to Lead</td>\n",
       "      <td>India</td>\n",
       "      <td>Select</td>\n",
       "      <td>Other</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Better Career Prospects</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Will revert after reading the email</td>\n",
       "      <td>Might be</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>01.High</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Prospect ID  Lead Number              Lead Origin  \\\n",
       "0  7927b2df-8bba-4d29-b9a2-b6e0beafe620       660737                      API   \n",
       "1  2a272436-5132-4136-86fa-dcc88c88f482       660728                      API   \n",
       "2  8cc8c611-a219-4f35-ad23-fdfd2656bd8a       660727  Landing Page Submission   \n",
       "3  0cc2df48-7cf4-4e39-9de9-19797f9b38cc       660719  Landing Page Submission   \n",
       "4  3256f628-e534-4826-9d63-4a8b88782852       660681  Landing Page Submission   \n",
       "\n",
       "      Lead Source Do Not Email Do Not Call  Converted  TotalVisits  \\\n",
       "0      Olark Chat           No          No          0          0.0   \n",
       "1  Organic Search           No          No          0          5.0   \n",
       "2  Direct Traffic           No          No          1          2.0   \n",
       "3  Direct Traffic           No          No          0          1.0   \n",
       "4          Google           No          No          1          2.0   \n",
       "\n",
       "   Total Time Spent on Website  Page Views Per Visit            Last Activity  \\\n",
       "0                            0                   0.0  Page Visited on Website   \n",
       "1                          674                   2.5             Email Opened   \n",
       "2                         1532                   2.0             Email Opened   \n",
       "3                          305                   1.0              Unreachable   \n",
       "4                         1428                   1.0        Converted to Lead   \n",
       "\n",
       "  Country           Specialization How did you hear about X Education  \\\n",
       "0     NaN                   Select                             Select   \n",
       "1   India                   Select                             Select   \n",
       "2   India  Business Administration                             Select   \n",
       "3   India    Media and Advertising                      Word Of Mouth   \n",
       "4   India                   Select                              Other   \n",
       "\n",
       "  What is your current occupation  \\\n",
       "0                      Unemployed   \n",
       "1                      Unemployed   \n",
       "2                         Student   \n",
       "3                      Unemployed   \n",
       "4                      Unemployed   \n",
       "\n",
       "  What matters most to you in choosing a course Search Magazine  \\\n",
       "0                       Better Career Prospects     No       No   \n",
       "1                       Better Career Prospects     No       No   \n",
       "2                       Better Career Prospects     No       No   \n",
       "3                       Better Career Prospects     No       No   \n",
       "4                       Better Career Prospects     No       No   \n",
       "\n",
       "  Newspaper Article X Education Forums Newspaper Digital Advertisement  \\\n",
       "0                No                 No        No                    No   \n",
       "1                No                 No        No                    No   \n",
       "2                No                 No        No                    No   \n",
       "3                No                 No        No                    No   \n",
       "4                No                 No        No                    No   \n",
       "\n",
       "  Through Recommendations Receive More Updates About Our Courses  \\\n",
       "0                      No                                     No   \n",
       "1                      No                                     No   \n",
       "2                      No                                     No   \n",
       "3                      No                                     No   \n",
       "4                      No                                     No   \n",
       "\n",
       "                                  Tags      Lead Quality  \\\n",
       "0          Interested in other courses  Low in Relevance   \n",
       "1                              Ringing               NaN   \n",
       "2  Will revert after reading the email          Might be   \n",
       "3                              Ringing          Not Sure   \n",
       "4  Will revert after reading the email          Might be   \n",
       "\n",
       "  Update me on Supply Chain Content Get updates on DM Content    Lead Profile  \\\n",
       "0                                No                        No          Select   \n",
       "1                                No                        No          Select   \n",
       "2                                No                        No  Potential Lead   \n",
       "3                                No                        No          Select   \n",
       "4                                No                        No          Select   \n",
       "\n",
       "     City Asymmetrique Activity Index Asymmetrique Profile Index  \\\n",
       "0  Select                   02.Medium                  02.Medium   \n",
       "1  Select                   02.Medium                  02.Medium   \n",
       "2  Mumbai                   02.Medium                    01.High   \n",
       "3  Mumbai                   02.Medium                    01.High   \n",
       "4  Mumbai                   02.Medium                    01.High   \n",
       "\n",
       "   Asymmetrique Activity Score  Asymmetrique Profile Score  \\\n",
       "0                         15.0                        15.0   \n",
       "1                         15.0                        15.0   \n",
       "2                         14.0                        20.0   \n",
       "3                         13.0                        17.0   \n",
       "4                         15.0                        18.0   \n",
       "\n",
       "  I agree to pay the amount through cheque  \\\n",
       "0                                       No   \n",
       "1                                       No   \n",
       "2                                       No   \n",
       "3                                       No   \n",
       "4                                       No   \n",
       "\n",
       "  A free copy of Mastering The Interview Last Notable Activity  \n",
       "0                                     No              Modified  \n",
       "1                                     No          Email Opened  \n",
       "2                                    Yes          Email Opened  \n",
       "3                                     No              Modified  \n",
       "4                                     No              Modified  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9240 records and 37 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prospect ID                                       object\n",
       "Lead Number                                        int64\n",
       "Lead Origin                                       object\n",
       "Lead Source                                       object\n",
       "Do Not Email                                      object\n",
       "Do Not Call                                       object\n",
       "Converted                                          int64\n",
       "TotalVisits                                      float64\n",
       "Total Time Spent on Website                        int64\n",
       "Page Views Per Visit                             float64\n",
       "Last Activity                                     object\n",
       "Country                                           object\n",
       "Specialization                                    object\n",
       "How did you hear about X Education                object\n",
       "What is your current occupation                   object\n",
       "What matters most to you in choosing a course     object\n",
       "Search                                            object\n",
       "Magazine                                          object\n",
       "Newspaper Article                                 object\n",
       "X Education Forums                                object\n",
       "Newspaper                                         object\n",
       "Digital Advertisement                             object\n",
       "Through Recommendations                           object\n",
       "Receive More Updates About Our Courses            object\n",
       "Tags                                              object\n",
       "Lead Quality                                      object\n",
       "Update me on Supply Chain Content                 object\n",
       "Get updates on DM Content                         object\n",
       "Lead Profile                                      object\n",
       "City                                              object\n",
       "Asymmetrique Activity Index                       object\n",
       "Asymmetrique Profile Index                        object\n",
       "Asymmetrique Activity Score                      float64\n",
       "Asymmetrique Profile Score                       float64\n",
       "I agree to pay the amount through cheque          object\n",
       "A free copy of Mastering The Interview            object\n",
       "Last Notable Activity                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9240 entries, 0 to 9239\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Prospect ID                                    9240 non-null   object \n",
      " 1   Lead Number                                    9240 non-null   int64  \n",
      " 2   Lead Origin                                    9240 non-null   object \n",
      " 3   Lead Source                                    9204 non-null   object \n",
      " 4   Do Not Email                                   9240 non-null   object \n",
      " 5   Do Not Call                                    9240 non-null   object \n",
      " 6   Converted                                      9240 non-null   int64  \n",
      " 7   TotalVisits                                    9103 non-null   float64\n",
      " 8   Total Time Spent on Website                    9240 non-null   int64  \n",
      " 9   Page Views Per Visit                           9103 non-null   float64\n",
      " 10  Last Activity                                  9137 non-null   object \n",
      " 11  Country                                        6779 non-null   object \n",
      " 12  Specialization                                 7802 non-null   object \n",
      " 13  How did you hear about X Education             7033 non-null   object \n",
      " 14  What is your current occupation                6550 non-null   object \n",
      " 15  What matters most to you in choosing a course  6531 non-null   object \n",
      " 16  Search                                         9240 non-null   object \n",
      " 17  Magazine                                       9240 non-null   object \n",
      " 18  Newspaper Article                              9240 non-null   object \n",
      " 19  X Education Forums                             9240 non-null   object \n",
      " 20  Newspaper                                      9240 non-null   object \n",
      " 21  Digital Advertisement                          9240 non-null   object \n",
      " 22  Through Recommendations                        9240 non-null   object \n",
      " 23  Receive More Updates About Our Courses         9240 non-null   object \n",
      " 24  Tags                                           5887 non-null   object \n",
      " 25  Lead Quality                                   4473 non-null   object \n",
      " 26  Update me on Supply Chain Content              9240 non-null   object \n",
      " 27  Get updates on DM Content                      9240 non-null   object \n",
      " 28  Lead Profile                                   6531 non-null   object \n",
      " 29  City                                           7820 non-null   object \n",
      " 30  Asymmetrique Activity Index                    5022 non-null   object \n",
      " 31  Asymmetrique Profile Index                     5022 non-null   object \n",
      " 32  Asymmetrique Activity Score                    5022 non-null   float64\n",
      " 33  Asymmetrique Profile Score                     5022 non-null   float64\n",
      " 34  I agree to pay the amount through cheque       9240 non-null   object \n",
      " 35  A free copy of Mastering The Interview         9240 non-null   object \n",
      " 36  Last Notable Activity                          9240 non-null   object \n",
      "dtypes: float64(4), int64(3), object(30)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.53896103896104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Converted Rate\n",
    "\n",
    "converted = (sum(df['Converted'])/len(df['Converted'].index))*100\n",
    "\n",
    "converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is almost 40% of conversion in the given data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Number</th>\n",
       "      <th>Converted</th>\n",
       "      <th>TotalVisits</th>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <th>Page Views Per Visit</th>\n",
       "      <th>Asymmetrique Activity Score</th>\n",
       "      <th>Asymmetrique Profile Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9240.000000</td>\n",
       "      <td>9240.000000</td>\n",
       "      <td>9103.000000</td>\n",
       "      <td>9240.000000</td>\n",
       "      <td>9103.000000</td>\n",
       "      <td>5022.000000</td>\n",
       "      <td>5022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>617188.435606</td>\n",
       "      <td>0.385390</td>\n",
       "      <td>3.445238</td>\n",
       "      <td>487.698268</td>\n",
       "      <td>2.362820</td>\n",
       "      <td>14.306252</td>\n",
       "      <td>16.344883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23405.995698</td>\n",
       "      <td>0.486714</td>\n",
       "      <td>4.854853</td>\n",
       "      <td>548.021466</td>\n",
       "      <td>2.161418</td>\n",
       "      <td>1.386694</td>\n",
       "      <td>1.811395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>579533.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>596484.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>615479.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>637387.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>660737.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>2272.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lead Number    Converted  TotalVisits  Total Time Spent on Website  \\\n",
       "count    9240.000000  9240.000000  9103.000000                  9240.000000   \n",
       "mean   617188.435606     0.385390     3.445238                   487.698268   \n",
       "std     23405.995698     0.486714     4.854853                   548.021466   \n",
       "min    579533.000000     0.000000     0.000000                     0.000000   \n",
       "25%    596484.500000     0.000000     1.000000                    12.000000   \n",
       "50%    615479.000000     0.000000     3.000000                   248.000000   \n",
       "75%    637387.250000     1.000000     5.000000                   936.000000   \n",
       "max    660737.000000     1.000000   251.000000                  2272.000000   \n",
       "\n",
       "       Page Views Per Visit  Asymmetrique Activity Score  \\\n",
       "count           9103.000000                  5022.000000   \n",
       "mean               2.362820                    14.306252   \n",
       "std                2.161418                     1.386694   \n",
       "min                0.000000                     7.000000   \n",
       "25%                1.000000                    14.000000   \n",
       "50%                2.000000                    14.000000   \n",
       "75%                3.000000                    15.000000   \n",
       "max               55.000000                    18.000000   \n",
       "\n",
       "       Asymmetrique Profile Score  \n",
       "count                 5022.000000  \n",
       "mean                    16.344883  \n",
       "std                      1.811395  \n",
       "min                     11.000000  \n",
       "25%                     15.000000  \n",
       "50%                     16.000000  \n",
       "75%                     18.000000  \n",
       "max                     20.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospect ID</th>\n",
       "      <th>Lead Origin</th>\n",
       "      <th>Lead Source</th>\n",
       "      <th>Do Not Email</th>\n",
       "      <th>Do Not Call</th>\n",
       "      <th>Last Activity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Specialization</th>\n",
       "      <th>How did you hear about X Education</th>\n",
       "      <th>What is your current occupation</th>\n",
       "      <th>What matters most to you in choosing a course</th>\n",
       "      <th>Search</th>\n",
       "      <th>Magazine</th>\n",
       "      <th>Newspaper Article</th>\n",
       "      <th>X Education Forums</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Digital Advertisement</th>\n",
       "      <th>Through Recommendations</th>\n",
       "      <th>Receive More Updates About Our Courses</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Lead Quality</th>\n",
       "      <th>Update me on Supply Chain Content</th>\n",
       "      <th>Get updates on DM Content</th>\n",
       "      <th>Lead Profile</th>\n",
       "      <th>City</th>\n",
       "      <th>Asymmetrique Activity Index</th>\n",
       "      <th>Asymmetrique Profile Index</th>\n",
       "      <th>I agree to pay the amount through cheque</th>\n",
       "      <th>A free copy of Mastering The Interview</th>\n",
       "      <th>Last Notable Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9204</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9137</td>\n",
       "      <td>6779</td>\n",
       "      <td>7802</td>\n",
       "      <td>7033</td>\n",
       "      <td>6550</td>\n",
       "      <td>6531</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>5887</td>\n",
       "      <td>4473</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>6531</td>\n",
       "      <td>7820</td>\n",
       "      <td>5022</td>\n",
       "      <td>5022</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9240</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>6c2a3e3f-de1a-49bc-9de5-b6a4c8a44cda</td>\n",
       "      <td>Landing Page Submission</td>\n",
       "      <td>Google</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Email Opened</td>\n",
       "      <td>India</td>\n",
       "      <td>Select</td>\n",
       "      <td>Select</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Better Career Prospects</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Will revert after reading the email</td>\n",
       "      <td>Might be</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Select</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>02.Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4886</td>\n",
       "      <td>2868</td>\n",
       "      <td>8506</td>\n",
       "      <td>9238</td>\n",
       "      <td>3437</td>\n",
       "      <td>6492</td>\n",
       "      <td>1942</td>\n",
       "      <td>5043</td>\n",
       "      <td>5600</td>\n",
       "      <td>6528</td>\n",
       "      <td>9226</td>\n",
       "      <td>9240</td>\n",
       "      <td>9238</td>\n",
       "      <td>9239</td>\n",
       "      <td>9239</td>\n",
       "      <td>9236</td>\n",
       "      <td>9233</td>\n",
       "      <td>9240</td>\n",
       "      <td>2072</td>\n",
       "      <td>1560</td>\n",
       "      <td>9240</td>\n",
       "      <td>9240</td>\n",
       "      <td>4146</td>\n",
       "      <td>3222</td>\n",
       "      <td>3839</td>\n",
       "      <td>2788</td>\n",
       "      <td>9240</td>\n",
       "      <td>6352</td>\n",
       "      <td>3407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Prospect ID              Lead Origin  \\\n",
       "count                                   9240                     9240   \n",
       "unique                                  9240                        5   \n",
       "top     6c2a3e3f-de1a-49bc-9de5-b6a4c8a44cda  Landing Page Submission   \n",
       "freq                                       1                     4886   \n",
       "\n",
       "       Lead Source Do Not Email Do Not Call Last Activity Country  \\\n",
       "count         9204         9240        9240          9137    6779   \n",
       "unique          21            2           2            17      38   \n",
       "top         Google           No          No  Email Opened   India   \n",
       "freq          2868         8506        9238          3437    6492   \n",
       "\n",
       "       Specialization How did you hear about X Education  \\\n",
       "count            7802                               7033   \n",
       "unique             19                                 10   \n",
       "top            Select                             Select   \n",
       "freq             1942                               5043   \n",
       "\n",
       "       What is your current occupation  \\\n",
       "count                             6550   \n",
       "unique                               6   \n",
       "top                         Unemployed   \n",
       "freq                              5600   \n",
       "\n",
       "       What matters most to you in choosing a course Search Magazine  \\\n",
       "count                                           6531   9240     9240   \n",
       "unique                                             3      2        1   \n",
       "top                          Better Career Prospects     No       No   \n",
       "freq                                            6528   9226     9240   \n",
       "\n",
       "       Newspaper Article X Education Forums Newspaper Digital Advertisement  \\\n",
       "count               9240               9240      9240                  9240   \n",
       "unique                 2                  2         2                     2   \n",
       "top                   No                 No        No                    No   \n",
       "freq                9238               9239      9239                  9236   \n",
       "\n",
       "       Through Recommendations Receive More Updates About Our Courses  \\\n",
       "count                     9240                                   9240   \n",
       "unique                       2                                      1   \n",
       "top                         No                                     No   \n",
       "freq                      9233                                   9240   \n",
       "\n",
       "                                       Tags Lead Quality  \\\n",
       "count                                  5887         4473   \n",
       "unique                                   26            5   \n",
       "top     Will revert after reading the email     Might be   \n",
       "freq                                   2072         1560   \n",
       "\n",
       "       Update me on Supply Chain Content Get updates on DM Content  \\\n",
       "count                               9240                      9240   \n",
       "unique                                 1                         1   \n",
       "top                                   No                        No   \n",
       "freq                                9240                      9240   \n",
       "\n",
       "       Lead Profile    City Asymmetrique Activity Index  \\\n",
       "count          6531    7820                        5022   \n",
       "unique            6       7                           3   \n",
       "top          Select  Mumbai                   02.Medium   \n",
       "freq           4146    3222                        3839   \n",
       "\n",
       "       Asymmetrique Profile Index I agree to pay the amount through cheque  \\\n",
       "count                        5022                                     9240   \n",
       "unique                          3                                        1   \n",
       "top                     02.Medium                                       No   \n",
       "freq                         2788                                     9240   \n",
       "\n",
       "       A free copy of Mastering The Interview Last Notable Activity  \n",
       "count                                    9240                  9240  \n",
       "unique                                      2                    16  \n",
       "top                                        No              Modified  \n",
       "freq                                     6352                  3407  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_var = [cname for cname in df.columns if df[cname].dtype == \"object\"]\n",
    "\n",
    "df[cat_var].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Value Count</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Get updates on DM Content</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I agree to pay the amount through cheque</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Receive More Updates About Our Courses</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magazine</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Update me on Supply Chain Content</th>\n",
       "      <td>1</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Through Recommendations</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital Advertisement</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newspaper</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X Education Forums</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A free copy of Mastering The Interview</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Search</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newspaper Article</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Converted</th>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do Not Call</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do Not Email</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What matters most to you in choosing a course</th>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asymmetrique Activity Index</th>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asymmetrique Profile Index</th>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead Origin</th>\n",
       "      <td>5</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead Quality</th>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is your current occupation</th>\n",
       "      <td>7</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead Profile</th>\n",
       "      <td>7</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How did you hear about X Education</th>\n",
       "      <td>11</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asymmetrique Profile Score</th>\n",
       "      <td>11</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asymmetrique Activity Score</th>\n",
       "      <td>13</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last Notable Activity</th>\n",
       "      <td>16</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last Activity</th>\n",
       "      <td>18</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specialization</th>\n",
       "      <td>20</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead Source</th>\n",
       "      <td>22</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>27</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>39</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalVisits</th>\n",
       "      <td>42</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Page Views Per Visit</th>\n",
       "      <td>115</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <td>1731</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lead Number</th>\n",
       "      <td>9240</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prospect ID</th>\n",
       "      <td>9240</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Unique Value Count    dtype\n",
       "Get updates on DM Content                                       1   object\n",
       "I agree to pay the amount through cheque                        1   object\n",
       "Receive More Updates About Our Courses                          1   object\n",
       "Magazine                                                        1   object\n",
       "Update me on Supply Chain Content                               1   object\n",
       "Through Recommendations                                         2   object\n",
       "Digital Advertisement                                           2   object\n",
       "Newspaper                                                       2   object\n",
       "X Education Forums                                              2   object\n",
       "A free copy of Mastering The Interview                          2   object\n",
       "Search                                                          2   object\n",
       "Newspaper Article                                               2   object\n",
       "Converted                                                       2    int64\n",
       "Do Not Call                                                     2   object\n",
       "Do Not Email                                                    2   object\n",
       "What matters most to you in choosing a course                   4   object\n",
       "Asymmetrique Activity Index                                     4   object\n",
       "Asymmetrique Profile Index                                      4   object\n",
       "Lead Origin                                                     5   object\n",
       "Lead Quality                                                    6   object\n",
       "What is your current occupation                                 7   object\n",
       "Lead Profile                                                    7   object\n",
       "City                                                            8   object\n",
       "How did you hear about X Education                             11   object\n",
       "Asymmetrique Profile Score                                     11  float64\n",
       "Asymmetrique Activity Score                                    13  float64\n",
       "Last Notable Activity                                          16   object\n",
       "Last Activity                                                  18   object\n",
       "Specialization                                                 20   object\n",
       "Lead Source                                                    22   object\n",
       "Tags                                                           27   object\n",
       "Country                                                        39   object\n",
       "TotalVisits                                                    42  float64\n",
       "Page Views Per Visit                                          115  float64\n",
       "Total Time Spent on Website                                  1731    int64\n",
       "Lead Number                                                  9240    int64\n",
       "Prospect ID                                                  9240   object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = pd.DataFrame(df.apply(lambda x: len(x.value_counts(dropna=False)), axis=0), columns=['Unique Value Count']).sort_values(by='Unique Value Count', ascending=True)\n",
    "\n",
    "unique_values['dtype'] = pd.DataFrame(df.dtypes)\n",
    "\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very important attribute to understand the variance in each column so that we can identify which columns have all values same and all values different to be used to decide whether or not to drop the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution of Unique Values of all Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################\n",
      "Unique value distribution of Lead Origin\n",
      "############################################\n",
      "Landing Page Submission    4886\n",
      "API                        3580\n",
      "Lead Add Form               718\n",
      "Lead Import                  55\n",
      "Quick Add Form                1\n",
      "Name: Lead Origin, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead Source\n",
      "############################################\n",
      "Google               2868\n",
      "Direct Traffic       2543\n",
      "Olark Chat           1755\n",
      "Organic Search       1154\n",
      "Reference             534\n",
      "Welingak Website      142\n",
      "Referral Sites        125\n",
      "Facebook               55\n",
      "NaN                    36\n",
      "bing                    6\n",
      "google                  5\n",
      "Click2call              4\n",
      "Press_Release           2\n",
      "Live Chat               2\n",
      "Social Media            2\n",
      "WeLearn                 1\n",
      "youtubechannel          1\n",
      "NC_EDM                  1\n",
      "blog                    1\n",
      "welearnblog_Home        1\n",
      "Pay per Click Ads       1\n",
      "testone                 1\n",
      "Name: Lead Source, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Do Not Email\n",
      "############################################\n",
      "No     8506\n",
      "Yes     734\n",
      "Name: Do Not Email, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Do Not Call\n",
      "############################################\n",
      "No     9238\n",
      "Yes       2\n",
      "Name: Do Not Call, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Converted\n",
      "############################################\n",
      "0    5679\n",
      "1    3561\n",
      "Name: Converted, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of TotalVisits\n",
      "############################################\n",
      "0.0      2189\n",
      "2.0      1680\n",
      "3.0      1306\n",
      "4.0      1120\n",
      "5.0       783\n",
      "         ... \n",
      "30.0        1\n",
      "43.0        1\n",
      "54.0        1\n",
      "115.0       1\n",
      "55.0        1\n",
      "Name: TotalVisits, Length: 42, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Last Activity\n",
      "############################################\n",
      "Email Opened                    3437\n",
      "SMS Sent                        2745\n",
      "Olark Chat Conversation          973\n",
      "Page Visited on Website          640\n",
      "Converted to Lead                428\n",
      "Email Bounced                    326\n",
      "Email Link Clicked               267\n",
      "Form Submitted on Website        116\n",
      "NaN                              103\n",
      "Unreachable                       93\n",
      "Unsubscribed                      61\n",
      "Had a Phone Conversation          30\n",
      "Approached upfront                 9\n",
      "View in browser link Clicked       6\n",
      "Email Marked Spam                  2\n",
      "Email Received                     2\n",
      "Resubscribed to emails             1\n",
      "Visited Booth in Tradeshow         1\n",
      "Name: Last Activity, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Country\n",
      "############################################\n",
      "India                   6492\n",
      "NaN                     2461\n",
      "United States             69\n",
      "United Arab Emirates      53\n",
      "Singapore                 24\n",
      "Saudi Arabia              21\n",
      "United Kingdom            15\n",
      "Australia                 13\n",
      "Qatar                     10\n",
      "Bahrain                    7\n",
      "Hong Kong                  7\n",
      "France                     6\n",
      "Oman                       6\n",
      "unknown                    5\n",
      "Nigeria                    4\n",
      "Kuwait                     4\n",
      "Germany                    4\n",
      "Canada                     4\n",
      "South Africa               4\n",
      "Sweden                     3\n",
      "Netherlands                2\n",
      "Ghana                      2\n",
      "Belgium                    2\n",
      "Philippines                2\n",
      "Bangladesh                 2\n",
      "China                      2\n",
      "Asia/Pacific Region        2\n",
      "Uganda                     2\n",
      "Italy                      2\n",
      "Indonesia                  1\n",
      "Denmark                    1\n",
      "Switzerland                1\n",
      "Tanzania                   1\n",
      "Sri Lanka                  1\n",
      "Russia                     1\n",
      "Kenya                      1\n",
      "Liberia                    1\n",
      "Malaysia                   1\n",
      "Vietnam                    1\n",
      "Name: Country, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Specialization\n",
      "############################################\n",
      "Select                               1942\n",
      "NaN                                  1438\n",
      "Finance Management                    976\n",
      "Human Resource Management             848\n",
      "Marketing Management                  838\n",
      "Operations Management                 503\n",
      "Business Administration               403\n",
      "IT Projects Management                366\n",
      "Supply Chain Management               349\n",
      "Banking, Investment And Insurance     338\n",
      "Travel and Tourism                    203\n",
      "Media and Advertising                 203\n",
      "International Business                178\n",
      "Healthcare Management                 159\n",
      "Hospitality Management                114\n",
      "E-COMMERCE                            112\n",
      "Retail Management                     100\n",
      "Rural and Agribusiness                 73\n",
      "E-Business                             57\n",
      "Services Excellence                    40\n",
      "Name: Specialization, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of How did you hear about X Education\n",
      "############################################\n",
      "Select                   5043\n",
      "NaN                      2207\n",
      "Online Search             808\n",
      "Word Of Mouth             348\n",
      "Student of SomeSchool     310\n",
      "Other                     186\n",
      "Multiple Sources          152\n",
      "Advertisements             70\n",
      "Social Media               67\n",
      "Email                      26\n",
      "SMS                        23\n",
      "Name: How did you hear about X Education, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of What is your current occupation\n",
      "############################################\n",
      "Unemployed              5600\n",
      "NaN                     2690\n",
      "Working Professional     706\n",
      "Student                  210\n",
      "Other                     16\n",
      "Housewife                 10\n",
      "Businessman                8\n",
      "Name: What is your current occupation, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of What matters most to you in choosing a course\n",
      "############################################\n",
      "Better Career Prospects      6528\n",
      "NaN                          2709\n",
      "Flexibility & Convenience       2\n",
      "Other                           1\n",
      "Name: What matters most to you in choosing a course, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Search\n",
      "############################################\n",
      "No     9226\n",
      "Yes      14\n",
      "Name: Search, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Magazine\n",
      "############################################\n",
      "No    9240\n",
      "Name: Magazine, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Newspaper Article\n",
      "############################################\n",
      "No     9238\n",
      "Yes       2\n",
      "Name: Newspaper Article, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of X Education Forums\n",
      "############################################\n",
      "No     9239\n",
      "Yes       1\n",
      "Name: X Education Forums, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Newspaper\n",
      "############################################\n",
      "No     9239\n",
      "Yes       1\n",
      "Name: Newspaper, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Digital Advertisement\n",
      "############################################\n",
      "No     9236\n",
      "Yes       4\n",
      "Name: Digital Advertisement, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Through Recommendations\n",
      "############################################\n",
      "No     9233\n",
      "Yes       7\n",
      "Name: Through Recommendations, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Receive More Updates About Our Courses\n",
      "############################################\n",
      "No    9240\n",
      "Name: Receive More Updates About Our Courses, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Tags\n",
      "############################################\n",
      "NaN                                                  3353\n",
      "Will revert after reading the email                  2072\n",
      "Ringing                                              1203\n",
      "Interested in other courses                           513\n",
      "Already a student                                     465\n",
      "Closed by Horizzon                                    358\n",
      "switched off                                          240\n",
      "Busy                                                  186\n",
      "Lost to EINS                                          175\n",
      "Not doing further education                           145\n",
      "Interested  in full time MBA                          117\n",
      "Graduation in progress                                111\n",
      "invalid number                                         83\n",
      "Diploma holder (Not Eligible)                          63\n",
      "wrong number given                                     47\n",
      "opp hangup                                             33\n",
      "number not provided                                    27\n",
      "in touch with EINS                                     12\n",
      "Lost to Others                                          7\n",
      "Want to take admission but has financial problems       6\n",
      "Still Thinking                                          6\n",
      "Interested in Next batch                                5\n",
      "In confusion whether part time or DLP                   5\n",
      "Lateral student                                         3\n",
      "Shall take in the next coming month                     2\n",
      "University not recognized                               2\n",
      "Recognition issue (DEC approval)                        1\n",
      "Name: Tags, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead Quality\n",
      "############################################\n",
      "NaN                  4767\n",
      "Might be             1560\n",
      "Not Sure             1092\n",
      "High in Relevance     637\n",
      "Worst                 601\n",
      "Low in Relevance      583\n",
      "Name: Lead Quality, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Update me on Supply Chain Content\n",
      "############################################\n",
      "No    9240\n",
      "Name: Update me on Supply Chain Content, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Get updates on DM Content\n",
      "############################################\n",
      "No    9240\n",
      "Name: Get updates on DM Content, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead Profile\n",
      "############################################\n",
      "Select                         4146\n",
      "NaN                            2709\n",
      "Potential Lead                 1613\n",
      "Other Leads                     487\n",
      "Student of SomeSchool           241\n",
      "Lateral Student                  24\n",
      "Dual Specialization Student      20\n",
      "Name: Lead Profile, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of City\n",
      "############################################\n",
      "Mumbai                         3222\n",
      "Select                         2249\n",
      "NaN                            1420\n",
      "Thane & Outskirts               752\n",
      "Other Cities                    686\n",
      "Other Cities of Maharashtra     457\n",
      "Other Metro Cities              380\n",
      "Tier II Cities                   74\n",
      "Name: City, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Asymmetrique Activity Index\n",
      "############################################\n",
      "NaN          4218\n",
      "02.Medium    3839\n",
      "01.High       821\n",
      "03.Low        362\n",
      "Name: Asymmetrique Activity Index, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Asymmetrique Profile Index\n",
      "############################################\n",
      "NaN          4218\n",
      "02.Medium    2788\n",
      "01.High      2203\n",
      "03.Low         31\n",
      "Name: Asymmetrique Profile Index, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Asymmetrique Activity Score\n",
      "############################################\n",
      "NaN     4218\n",
      "14.0    1771\n",
      "15.0    1293\n",
      "13.0     775\n",
      "16.0     467\n",
      "17.0     349\n",
      "12.0     196\n",
      "11.0      95\n",
      "10.0      57\n",
      "9.0        9\n",
      "18.0       5\n",
      "8.0        4\n",
      "7.0        1\n",
      "Name: Asymmetrique Activity Score, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Asymmetrique Profile Score\n",
      "############################################\n",
      "NaN     4218\n",
      "15.0    1759\n",
      "18.0    1071\n",
      "16.0     599\n",
      "17.0     579\n",
      "20.0     308\n",
      "19.0     245\n",
      "14.0     226\n",
      "13.0     204\n",
      "12.0      22\n",
      "11.0       9\n",
      "Name: Asymmetrique Profile Score, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of I agree to pay the amount through cheque\n",
      "############################################\n",
      "No    9240\n",
      "Name: I agree to pay the amount through cheque, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of A free copy of Mastering The Interview\n",
      "############################################\n",
      "No     6352\n",
      "Yes    2888\n",
      "Name: A free copy of Mastering The Interview, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Last Notable Activity\n",
      "############################################\n",
      "Modified                        3407\n",
      "Email Opened                    2827\n",
      "SMS Sent                        2172\n",
      "Page Visited on Website          318\n",
      "Olark Chat Conversation          183\n",
      "Email Link Clicked               173\n",
      "Email Bounced                     60\n",
      "Unsubscribed                      47\n",
      "Unreachable                       32\n",
      "Had a Phone Conversation          14\n",
      "Email Marked Spam                  2\n",
      "Form Submitted on Website          1\n",
      "Approached upfront                 1\n",
      "Resubscribed to emails             1\n",
      "View in browser link Clicked       1\n",
      "Email Received                     1\n",
      "Name: Last Notable Activity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('Prospect ID')\n",
    "cols.remove('Lead Number')\n",
    "cols.remove('Total Time Spent on Website')\n",
    "cols.remove('Page Views Per Visit')\n",
    "\n",
    "for col in cols:\n",
    "    print('\\n############################################')\n",
    "    print('Unique value distribution of ' + str(col))\n",
    "    print('############################################')\n",
    "    print(df[col].value_counts(dropna=False).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Max Values of Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lead Number</th>\n",
       "      <td>660737.0</td>\n",
       "      <td>579533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Converted</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalVisits</th>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Time Spent on Website</th>\n",
       "      <td>2272.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Page Views Per Visit</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asymmetrique Activity Score</th>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asymmetrique Profile Score</th>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Max       Min\n",
       "Lead Number                  660737.0  579533.0\n",
       "Converted                         1.0       0.0\n",
       "TotalVisits                     251.0       0.0\n",
       "Total Time Spent on Website    2272.0       0.0\n",
       "Page Views Per Visit             55.0       0.0\n",
       "Asymmetrique Activity Score      18.0       7.0\n",
       "Asymmetrique Profile Score       20.0      11.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all the values of the variables are in the same scale\n",
    "\n",
    "numeric_cols = [cname for cname in df.columns if \n",
    "                                df[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "Max = pd.DataFrame(df[numeric_cols].max().rename('Max'))\n",
    "Min = pd.DataFrame(df[numeric_cols].min().rename('Min'))\n",
    "\n",
    "pd.concat([Max, Min], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Columns with Single/All Different Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['Prospect ID', 'Lead Number', 'Get updates on DM Content', 'I agree to pay the amount through cheque', \n",
    "            'Receive More Updates About Our Courses', 'Magazine', 'Update me on Supply Chain Content']\n",
    "\n",
    "df.drop(drop_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Columns with Very High Imabalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below columns have a very high number of a single value compared to the other hence not useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################\n",
      "Unique value distribution of Through Recommendations\n",
      "############################################\n",
      "No     9233\n",
      "Yes       7\n",
      "Name: Through Recommendations, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Digital Advertisement\n",
      "############################################\n",
      "No     9236\n",
      "Yes       4\n",
      "Name: Digital Advertisement, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Newspaper\n",
      "############################################\n",
      "No     9239\n",
      "Yes       1\n",
      "Name: Newspaper, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of X Education Forums\n",
      "############################################\n",
      "No     9239\n",
      "Yes       1\n",
      "Name: X Education Forums, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Search\n",
      "############################################\n",
      "No     9226\n",
      "Yes      14\n",
      "Name: Search, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Newspaper Article\n",
      "############################################\n",
      "No     9238\n",
      "Yes       2\n",
      "Name: Newspaper Article, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of What matters most to you in choosing a course\n",
      "############################################\n",
      "Better Career Prospects      6528\n",
      "NaN                          2709\n",
      "Flexibility & Convenience       2\n",
      "Other                           1\n",
      "Name: What matters most to you in choosing a course, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Do Not Call\n",
      "############################################\n",
      "No     9238\n",
      "Yes       2\n",
      "Name: Do Not Call, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in ['Through Recommendations', 'Digital Advertisement', 'Newspaper', 'X Education Forums', 'Search', \n",
    "            'Newspaper Article', 'What matters most to you in choosing a course', 'Do Not Call']:\n",
    "    print('\\n############################################')\n",
    "    print('Unique value distribution of ' + str(col))\n",
    "    print('############################################')\n",
    "    print(df[col].value_counts(dropna=False).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['Through Recommendations', 'Digital Advertisement', 'Newspaper', 'X Education Forums', 'Search', \n",
    "            'Newspaper Article', 'What matters most to you in choosing a course', 'Do Not Call']\n",
    "\n",
    "df.drop(drop_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droping Insignificant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we observe the values of city column, all of them are from India which makes the column Country not useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9240 entries, 0 to 9239\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Lead Origin                             9240 non-null   object \n",
      " 1   Lead Source                             9204 non-null   object \n",
      " 2   Do Not Email                            9240 non-null   object \n",
      " 3   Converted                               9240 non-null   int64  \n",
      " 4   TotalVisits                             9103 non-null   float64\n",
      " 5   Total Time Spent on Website             9240 non-null   int64  \n",
      " 6   Page Views Per Visit                    9103 non-null   float64\n",
      " 7   Last Activity                           9137 non-null   object \n",
      " 8   Specialization                          7802 non-null   object \n",
      " 9   How did you hear about X Education      7033 non-null   object \n",
      " 10  What is your current occupation         6550 non-null   object \n",
      " 11  Tags                                    5887 non-null   object \n",
      " 12  Lead Quality                            4473 non-null   object \n",
      " 13  Lead Profile                            6531 non-null   object \n",
      " 14  City                                    7820 non-null   object \n",
      " 15  Asymmetrique Activity Index             5022 non-null   object \n",
      " 16  Asymmetrique Profile Index              5022 non-null   object \n",
      " 17  Asymmetrique Activity Score             5022 non-null   float64\n",
      " 18  Asymmetrique Profile Score              5022 non-null   float64\n",
      " 19  A free copy of Mastering The Interview  9240 non-null   object \n",
      " 20  Last Notable Activity                   9240 non-null   object \n",
      "dtypes: float64(4), int64(2), object(15)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=\n",
    "            {\n",
    "             \"Lead Origin\":\"Lead_Origin\",\n",
    "             \"Lead Source\":\"Lead_Source\",\n",
    "             \"Do Not Email\":\"No_Email\",\n",
    "             \"TotalVisits\":\"Total_Visits\",\n",
    "             \"Total Time Spent on Website\":\"Time_On_Website\",\n",
    "             \"Page Views Per Visit\":\"Page_Views\",\n",
    "             \"Last Activity\":\"Last_Activity\",\n",
    "             \"How did you hear about X Education\":\"Hear\",\n",
    "             \"What is your current occupation\":\"Occupation\",\n",
    "             \"Lead Quality\":\"Lead_Quality\",\n",
    "             \"Lead Profile\":\"Lead_Profile\",\n",
    "             \"Asymmetrique Activity Index\":\"Activity_Index\",\n",
    "             \"Asymmetrique Profile Index\":\"Profile_Index\",\n",
    "             \"Asymmetrique Activity Score\":\"Activity_Score\",\n",
    "             \"Asymmetrique Profile Score\":\"Profile_Score\",\n",
    "             \"A free copy of Mastering The Interview\":\"Free_Copy\",\n",
    "             \"Last Notable Activity\":\"Last_Notable_Activity\"\n",
    "            }, \n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9240 entries, 0 to 9239\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Lead_Origin            9240 non-null   object \n",
      " 1   Lead_Source            9204 non-null   object \n",
      " 2   No_Email               9240 non-null   object \n",
      " 3   Converted              9240 non-null   int64  \n",
      " 4   Total_Visits           9103 non-null   float64\n",
      " 5   Time_On_Website        9240 non-null   int64  \n",
      " 6   Page_Views             9103 non-null   float64\n",
      " 7   Last_Activity          9137 non-null   object \n",
      " 8   Specialization         7802 non-null   object \n",
      " 9   Hear                   7033 non-null   object \n",
      " 10  Occupation             6550 non-null   object \n",
      " 11  Tags                   5887 non-null   object \n",
      " 12  Lead_Quality           4473 non-null   object \n",
      " 13  Lead_Profile           6531 non-null   object \n",
      " 14  City                   7820 non-null   object \n",
      " 15  Activity_Index         5022 non-null   object \n",
      " 16  Profile_Index          5022 non-null   object \n",
      " 17  Activity_Score         5022 non-null   float64\n",
      " 18  Profile_Score          5022 non-null   float64\n",
      " 19  Free_Copy              9240 non-null   object \n",
      " 20  Last_Notable_Activity  9240 non-null   object \n",
      "dtypes: float64(4), int64(2), object(15)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Origin\n",
      "############################################\n",
      "Landing Page Submission    4886\n",
      "API                        3580\n",
      "Lead Add Form               718\n",
      "Lead Import                  55\n",
      "Quick Add Form                1\n",
      "Name: Lead_Origin, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Source\n",
      "############################################\n",
      "Google               2868\n",
      "Direct Traffic       2543\n",
      "Olark Chat           1755\n",
      "Organic Search       1154\n",
      "Reference             534\n",
      "Welingak Website      142\n",
      "Referral Sites        125\n",
      "Facebook               55\n",
      "NaN                    36\n",
      "bing                    6\n",
      "google                  5\n",
      "Click2call              4\n",
      "Press_Release           2\n",
      "Live Chat               2\n",
      "Social Media            2\n",
      "WeLearn                 1\n",
      "youtubechannel          1\n",
      "NC_EDM                  1\n",
      "blog                    1\n",
      "welearnblog_Home        1\n",
      "Pay per Click Ads       1\n",
      "testone                 1\n",
      "Name: Lead_Source, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of No_Email\n",
      "############################################\n",
      "No     8506\n",
      "Yes     734\n",
      "Name: No_Email, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Last_Activity\n",
      "############################################\n",
      "Email Opened                    3437\n",
      "SMS Sent                        2745\n",
      "Olark Chat Conversation          973\n",
      "Page Visited on Website          640\n",
      "Converted to Lead                428\n",
      "Email Bounced                    326\n",
      "Email Link Clicked               267\n",
      "Form Submitted on Website        116\n",
      "NaN                              103\n",
      "Unreachable                       93\n",
      "Unsubscribed                      61\n",
      "Had a Phone Conversation          30\n",
      "Approached upfront                 9\n",
      "View in browser link Clicked       6\n",
      "Email Marked Spam                  2\n",
      "Email Received                     2\n",
      "Resubscribed to emails             1\n",
      "Visited Booth in Tradeshow         1\n",
      "Name: Last_Activity, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Specialization\n",
      "############################################\n",
      "Select                               1942\n",
      "NaN                                  1438\n",
      "Finance Management                    976\n",
      "Human Resource Management             848\n",
      "Marketing Management                  838\n",
      "Operations Management                 503\n",
      "Business Administration               403\n",
      "IT Projects Management                366\n",
      "Supply Chain Management               349\n",
      "Banking, Investment And Insurance     338\n",
      "Travel and Tourism                    203\n",
      "Media and Advertising                 203\n",
      "International Business                178\n",
      "Healthcare Management                 159\n",
      "Hospitality Management                114\n",
      "E-COMMERCE                            112\n",
      "Retail Management                     100\n",
      "Rural and Agribusiness                 73\n",
      "E-Business                             57\n",
      "Services Excellence                    40\n",
      "Name: Specialization, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Hear\n",
      "############################################\n",
      "Select                   5043\n",
      "NaN                      2207\n",
      "Online Search             808\n",
      "Word Of Mouth             348\n",
      "Student of SomeSchool     310\n",
      "Other                     186\n",
      "Multiple Sources          152\n",
      "Advertisements             70\n",
      "Social Media               67\n",
      "Email                      26\n",
      "SMS                        23\n",
      "Name: Hear, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Occupation\n",
      "############################################\n",
      "Unemployed              5600\n",
      "NaN                     2690\n",
      "Working Professional     706\n",
      "Student                  210\n",
      "Other                     16\n",
      "Housewife                 10\n",
      "Businessman                8\n",
      "Name: Occupation, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Tags\n",
      "############################################\n",
      "NaN                                                  3353\n",
      "Will revert after reading the email                  2072\n",
      "Ringing                                              1203\n",
      "Interested in other courses                           513\n",
      "Already a student                                     465\n",
      "Closed by Horizzon                                    358\n",
      "switched off                                          240\n",
      "Busy                                                  186\n",
      "Lost to EINS                                          175\n",
      "Not doing further education                           145\n",
      "Interested  in full time MBA                          117\n",
      "Graduation in progress                                111\n",
      "invalid number                                         83\n",
      "Diploma holder (Not Eligible)                          63\n",
      "wrong number given                                     47\n",
      "opp hangup                                             33\n",
      "number not provided                                    27\n",
      "in touch with EINS                                     12\n",
      "Lost to Others                                          7\n",
      "Want to take admission but has financial problems       6\n",
      "Still Thinking                                          6\n",
      "Interested in Next batch                                5\n",
      "In confusion whether part time or DLP                   5\n",
      "Lateral student                                         3\n",
      "Shall take in the next coming month                     2\n",
      "University not recognized                               2\n",
      "Recognition issue (DEC approval)                        1\n",
      "Name: Tags, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Quality\n",
      "############################################\n",
      "NaN                  4767\n",
      "Might be             1560\n",
      "Not Sure             1092\n",
      "High in Relevance     637\n",
      "Worst                 601\n",
      "Low in Relevance      583\n",
      "Name: Lead_Quality, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Profile\n",
      "############################################\n",
      "Select                         4146\n",
      "NaN                            2709\n",
      "Potential Lead                 1613\n",
      "Other Leads                     487\n",
      "Student of SomeSchool           241\n",
      "Lateral Student                  24\n",
      "Dual Specialization Student      20\n",
      "Name: Lead_Profile, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of City\n",
      "############################################\n",
      "Mumbai                         3222\n",
      "Select                         2249\n",
      "NaN                            1420\n",
      "Thane & Outskirts               752\n",
      "Other Cities                    686\n",
      "Other Cities of Maharashtra     457\n",
      "Other Metro Cities              380\n",
      "Tier II Cities                   74\n",
      "Name: City, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Activity_Index\n",
      "############################################\n",
      "NaN          4218\n",
      "02.Medium    3839\n",
      "01.High       821\n",
      "03.Low        362\n",
      "Name: Activity_Index, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Free_Copy\n",
      "############################################\n",
      "No     6352\n",
      "Yes    2888\n",
      "Name: Free_Copy, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Last_Notable_Activity\n",
      "############################################\n",
      "Modified                        3407\n",
      "Email Opened                    2827\n",
      "SMS Sent                        2172\n",
      "Page Visited on Website          318\n",
      "Olark Chat Conversation          183\n",
      "Email Link Clicked               173\n",
      "Email Bounced                     60\n",
      "Unsubscribed                      47\n",
      "Unreachable                       32\n",
      "Had a Phone Conversation          14\n",
      "Email Marked Spam                  2\n",
      "Form Submitted on Website          1\n",
      "Approached upfront                 1\n",
      "Resubscribed to emails             1\n",
      "View in browser link Clicked       1\n",
      "Email Received                     1\n",
      "Name: Last_Notable_Activity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('Time_On_Website')\n",
    "cols.remove('Page_Views')\n",
    "cols.remove('Total_Visits')\n",
    "cols.remove('Profile_Index')\n",
    "cols.remove('Activity_Score')\n",
    "cols.remove('Profile_Score')\n",
    "cols.remove('Converted')\n",
    "\n",
    "for col in cols:\n",
    "    print('\\n############################################')\n",
    "    print('Unique value distribution of ' + str(col))\n",
    "    print('############################################')\n",
    "    print(df[col].value_counts(dropna=False).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [cname for cname in df.columns if df[cname].dtype == \"object\"]\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all text to lower helps in identifying duplicate values due to case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################\n",
      "Unique values of Lead_Origin\n",
      "################################\n",
      "0                        api\n",
      "1    landing page submission\n",
      "2              lead add form\n",
      "3                lead import\n",
      "4             quick add form\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Lead_Source\n",
      "################################\n",
      "11                 bing\n",
      "9                  blog\n",
      "14           click2call\n",
      "2        direct traffic\n",
      "7              facebook\n",
      "3                google\n",
      "15            live chat\n",
      "20               nc_edm\n",
      "0            olark chat\n",
      "1        organic search\n",
      "10    pay per click ads\n",
      "19        press_release\n",
      "6             reference\n",
      "4        referral sites\n",
      "12         social media\n",
      "18              testone\n",
      "13              welearn\n",
      "16     welearnblog_home\n",
      "5      welingak website\n",
      "17       youtubechannel\n",
      "8                   NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of No_Email\n",
      "################################\n",
      "0     no\n",
      "1    yes\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Last_Activity\n",
      "################################\n",
      "12              approached upfront\n",
      "3                converted to lead\n",
      "5                    email bounced\n",
      "6               email link clicked\n",
      "17               email marked spam\n",
      "1                     email opened\n",
      "16                  email received\n",
      "7        form submitted on website\n",
      "9         had a phone conversation\n",
      "4          olark chat conversation\n",
      "0          page visited on website\n",
      "15          resubscribed to emails\n",
      "13                        sms sent\n",
      "2                      unreachable\n",
      "8                     unsubscribed\n",
      "10    view in browser link clicked\n",
      "14      visited booth in tradeshow\n",
      "11                             NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Specialization\n",
      "################################\n",
      "10    banking, investment and insurance\n",
      "1               business administration\n",
      "19                           e-business\n",
      "12                           e-commerce\n",
      "6                    finance management\n",
      "18                healthcare management\n",
      "16               hospitality management\n",
      "8             human resource management\n",
      "11               international business\n",
      "5                it projects management\n",
      "9                  marketing management\n",
      "2                 media and advertising\n",
      "13                operations management\n",
      "14                    retail management\n",
      "17               rural and agribusiness\n",
      "0                                select\n",
      "15                  services excellence\n",
      "4               supply chain management\n",
      "7                    travel and tourism\n",
      "3                                   NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Hear\n",
      "################################\n",
      "6            advertisements\n",
      "8                     email\n",
      "5          multiple sources\n",
      "4             online search\n",
      "2                     other\n",
      "0                    select\n",
      "10                      sms\n",
      "9              social media\n",
      "7     student of someschool\n",
      "1             word of mouth\n",
      "3                       NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Occupation\n",
      "################################\n",
      "4             businessman\n",
      "6               housewife\n",
      "5                   other\n",
      "1                 student\n",
      "0              unemployed\n",
      "3    working professional\n",
      "2                     NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Tags\n",
      "################################\n",
      "9                                     already a student\n",
      "6                                                  busy\n",
      "12                                   closed by horizzon\n",
      "10                        diploma holder (not eligible)\n",
      "11                               graduation in progress\n",
      "5                 in confusion whether part time or dlp\n",
      "8                                    in touch with eins\n",
      "18                         interested  in full time mba\n",
      "23                             interested in next batch\n",
      "0                           interested in other courses\n",
      "16                                       invalid number\n",
      "22                                      lateral student\n",
      "4                                          lost to eins\n",
      "20                                       lost to others\n",
      "15                          not doing further education\n",
      "13                                  number not provided\n",
      "14                                           opp hangup\n",
      "24                     recognition issue (dec approval)\n",
      "1                                               ringing\n",
      "21                  shall take in the next coming month\n",
      "19                                       still thinking\n",
      "7                                          switched off\n",
      "26                            university not recognized\n",
      "25    want to take admission but has financial problems\n",
      "2                   will revert after reading the email\n",
      "17                                   wrong number given\n",
      "3                                                   NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Lead_Quality\n",
      "################################\n",
      "5    high in relevance\n",
      "0     low in relevance\n",
      "2             might be\n",
      "3             not sure\n",
      "4                worst\n",
      "1                  NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Lead_Profile\n",
      "################################\n",
      "5    dual specialization student\n",
      "4                lateral student\n",
      "3                    other leads\n",
      "1                 potential lead\n",
      "0                         select\n",
      "6          student of someschool\n",
      "2                            NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of City\n",
      "################################\n",
      "1                         mumbai\n",
      "5                   other cities\n",
      "6    other cities of maharashtra\n",
      "4             other metro cities\n",
      "0                         select\n",
      "3              thane & outskirts\n",
      "7                 tier ii cities\n",
      "2                            NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Activity_Index\n",
      "################################\n",
      "1      01.high\n",
      "0    02.medium\n",
      "2       03.low\n",
      "3          NaN\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Free_Copy\n",
      "################################\n",
      "0     no\n",
      "1    yes\n",
      "dtype: object\n",
      "\n",
      "################################\n",
      "Unique values of Last_Notable_Activity\n",
      "################################\n",
      "10              approached upfront\n",
      "3                    email bounced\n",
      "4               email link clicked\n",
      "15               email marked spam\n",
      "1                     email opened\n",
      "14                  email received\n",
      "13       form submitted on website\n",
      "7         had a phone conversation\n",
      "0                         modified\n",
      "8          olark chat conversation\n",
      "2          page visited on website\n",
      "11          resubscribed to emails\n",
      "9                         sms sent\n",
      "5                      unreachable\n",
      "6                     unsubscribed\n",
      "12    view in browser link clicked\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('Time_On_Website')\n",
    "cols.remove('Page_Views')\n",
    "cols.remove('Total_Visits')\n",
    "cols.remove('Profile_Index')\n",
    "cols.remove('Activity_Score')\n",
    "cols.remove('Profile_Score')\n",
    "cols.remove('Converted')\n",
    "\n",
    "for col in cols:\n",
    "    print('\\n################################')\n",
    "    print('Unique values of ' + str(col))\n",
    "    print('################################')\n",
    "    print(pd.Series(df[col].unique()).sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    7958\n",
       "True     1282\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1282 duplicate rows in the data set. We can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead_Origin</th>\n",
       "      <th>Lead_Source</th>\n",
       "      <th>No_Email</th>\n",
       "      <th>Converted</th>\n",
       "      <th>Total_Visits</th>\n",
       "      <th>Time_On_Website</th>\n",
       "      <th>Page_Views</th>\n",
       "      <th>Last_Activity</th>\n",
       "      <th>Specialization</th>\n",
       "      <th>Hear</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Lead_Quality</th>\n",
       "      <th>Lead_Profile</th>\n",
       "      <th>City</th>\n",
       "      <th>Activity_Index</th>\n",
       "      <th>Profile_Index</th>\n",
       "      <th>Activity_Score</th>\n",
       "      <th>Profile_Score</th>\n",
       "      <th>Free_Copy</th>\n",
       "      <th>Last_Notable_Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>olark chat conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>olark chat conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>olark chat conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>olark chat conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>olark chat conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9136</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sms sent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>olark chat conversation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sms sent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>email opened</td>\n",
       "      <td>select</td>\n",
       "      <td>select</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>already a student</td>\n",
       "      <td>NaN</td>\n",
       "      <td>potential lead</td>\n",
       "      <td>select</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>no</td>\n",
       "      <td>email opened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>api</td>\n",
       "      <td>olark chat</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sms sent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01.high</td>\n",
       "      <td>02.medium</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>no</td>\n",
       "      <td>sms sent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lead_Origin Lead_Source No_Email  Converted  Total_Visits  \\\n",
       "16           api  olark chat       no          0           0.0   \n",
       "47           api  olark chat       no          0           0.0   \n",
       "49           api  olark chat       no          0           0.0   \n",
       "83           api  olark chat       no          0           0.0   \n",
       "190          api  olark chat       no          0           0.0   \n",
       "...          ...         ...      ...        ...           ...   \n",
       "9136         api  olark chat       no          0           0.0   \n",
       "9137         api  olark chat       no          0           0.0   \n",
       "9165         api  olark chat       no          1           0.0   \n",
       "9170         api  olark chat       no          0           0.0   \n",
       "9187         api  olark chat       no          1           0.0   \n",
       "\n",
       "      Time_On_Website  Page_Views            Last_Activity Specialization  \\\n",
       "16                  0         0.0  olark chat conversation            NaN   \n",
       "47                  0         0.0  olark chat conversation            NaN   \n",
       "49                  0         0.0  olark chat conversation            NaN   \n",
       "83                  0         0.0  olark chat conversation            NaN   \n",
       "190                 0         0.0  olark chat conversation            NaN   \n",
       "...               ...         ...                      ...            ...   \n",
       "9136                0         0.0                 sms sent            NaN   \n",
       "9137                0         0.0  olark chat conversation            NaN   \n",
       "9165                0         0.0                 sms sent            NaN   \n",
       "9170                0         0.0             email opened         select   \n",
       "9187                0         0.0                 sms sent            NaN   \n",
       "\n",
       "        Hear  Occupation               Tags Lead_Quality    Lead_Profile  \\\n",
       "16       NaN         NaN                NaN          NaN             NaN   \n",
       "47       NaN         NaN                NaN          NaN             NaN   \n",
       "49       NaN         NaN                NaN          NaN             NaN   \n",
       "83       NaN         NaN                NaN          NaN             NaN   \n",
       "190      NaN         NaN                NaN          NaN             NaN   \n",
       "...      ...         ...                ...          ...             ...   \n",
       "9136     NaN         NaN                NaN          NaN             NaN   \n",
       "9137     NaN         NaN                NaN          NaN             NaN   \n",
       "9165     NaN         NaN                NaN          NaN             NaN   \n",
       "9170  select  unemployed  already a student          NaN  potential lead   \n",
       "9187     NaN         NaN                NaN          NaN             NaN   \n",
       "\n",
       "        City Activity_Index Profile_Index  Activity_Score  Profile_Score  \\\n",
       "16       NaN        01.high     02.medium            17.0           15.0   \n",
       "47       NaN        01.high     02.medium            17.0           15.0   \n",
       "49       NaN        01.high     02.medium            17.0           15.0   \n",
       "83       NaN        01.high     02.medium            17.0           15.0   \n",
       "190      NaN        01.high     02.medium            17.0           15.0   \n",
       "...      ...            ...           ...             ...            ...   \n",
       "9136     NaN      02.medium     02.medium            14.0           15.0   \n",
       "9137     NaN        01.high     02.medium            17.0           15.0   \n",
       "9165     NaN        01.high     02.medium            16.0           15.0   \n",
       "9170  select        01.high     02.medium            17.0           16.0   \n",
       "9187     NaN        01.high     02.medium            16.0           15.0   \n",
       "\n",
       "     Free_Copy Last_Notable_Activity  \n",
       "16          no              modified  \n",
       "47          no              modified  \n",
       "49          no              modified  \n",
       "83          no              modified  \n",
       "190         no              modified  \n",
       "...        ...                   ...  \n",
       "9136        no              modified  \n",
       "9137        no              modified  \n",
       "9165        no              modified  \n",
       "9170        no          email opened  \n",
       "9187        no              sms sent  \n",
       "\n",
       "[1282 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7958 entries, 0 to 9239\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Lead_Origin            7958 non-null   object \n",
      " 1   Lead_Source            7925 non-null   object \n",
      " 2   No_Email               7958 non-null   object \n",
      " 3   Converted              7958 non-null   int64  \n",
      " 4   Total_Visits           7821 non-null   float64\n",
      " 5   Time_On_Website        7958 non-null   int64  \n",
      " 6   Page_Views             7821 non-null   float64\n",
      " 7   Last_Activity          7855 non-null   object \n",
      " 8   Specialization         7259 non-null   object \n",
      " 9   Hear                   6490 non-null   object \n",
      " 10  Occupation             6007 non-null   object \n",
      " 11  Tags                   5556 non-null   object \n",
      " 12  Lead_Quality           4253 non-null   object \n",
      " 13  Lead_Profile           5988 non-null   object \n",
      " 14  City                   7276 non-null   object \n",
      " 15  Activity_Index         4444 non-null   object \n",
      " 16  Profile_Index          4444 non-null   object \n",
      " 17  Activity_Score         4444 non-null   float64\n",
      " 18  Profile_Score          4444 non-null   float64\n",
      " 19  Free_Copy              7958 non-null   object \n",
      " 20  Last_Notable_Activity  7958 non-null   object \n",
      "dtypes: float64(4), int64(2), object(15)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lead_Quality      46.56\n",
       "Profile_Score     44.16\n",
       "Activity_Score    44.16\n",
       "Profile_Index     44.16\n",
       "Activity_Index    44.16\n",
       "Tags              30.18\n",
       "Lead_Profile      24.75\n",
       "Occupation        24.52\n",
       "Hear              18.45\n",
       "Specialization     8.78\n",
       "City               8.57\n",
       "Page_Views         1.72\n",
       "Total_Visits       1.72\n",
       "Last_Activity      1.29\n",
       "Lead_Source        0.41\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_series = pd.Series(round(100*(df.isnull().sum(axis=0)/len(df.index)), 2).sort_values(ascending = False))\n",
    "null_series.loc[null_series.values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns whose missing value % is >= **30%** as they won't help in the analysis and imputing them would only add more bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['Lead_Quality','Profile_Score','Activity_Score','Profile_Index','Activity_Index','Tags']\n",
    "\n",
    "df.drop(drop_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7958 entries, 0 to 9239\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Lead_Origin            7958 non-null   object \n",
      " 1   Lead_Source            7925 non-null   object \n",
      " 2   No_Email               7958 non-null   object \n",
      " 3   Converted              7958 non-null   int64  \n",
      " 4   Total_Visits           7821 non-null   float64\n",
      " 5   Time_On_Website        7958 non-null   int64  \n",
      " 6   Page_Views             7821 non-null   float64\n",
      " 7   Last_Activity          7855 non-null   object \n",
      " 8   Specialization         7259 non-null   object \n",
      " 9   Hear                   6490 non-null   object \n",
      " 10  Occupation             6007 non-null   object \n",
      " 11  Lead_Profile           5988 non-null   object \n",
      " 12  City                   7276 non-null   object \n",
      " 13  Free_Copy              7958 non-null   object \n",
      " 14  Last_Notable_Activity  7958 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 994.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lead_Profile      24.75\n",
       "Occupation        24.52\n",
       "Hear              18.45\n",
       "Specialization     8.78\n",
       "City               8.57\n",
       "Page_Views         1.72\n",
       "Total_Visits       1.72\n",
       "Last_Activity      1.29\n",
       "Lead_Source        0.41\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_series = pd.Series(round(100*(df.isnull().sum(axis=0)/len(df.index)), 2).sort_values(ascending = False))\n",
    "null_series.loc[null_series.values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the different unique values of the missing value columns to see how we can impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Profile\n",
      "############################################\n",
      "select                         3751\n",
      "NaN                            1970\n",
      "potential lead                 1508\n",
      "other leads                     484\n",
      "student of someschool           201\n",
      "lateral student                  24\n",
      "dual specialization student      20\n",
      "Name: Lead_Profile, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Occupation\n",
      "############################################\n",
      "unemployed              5150\n",
      "NaN                     1951\n",
      "working professional     638\n",
      "student                  185\n",
      "other                     16\n",
      "housewife                 10\n",
      "businessman                8\n",
      "Name: Occupation, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Hear\n",
      "############################################\n",
      "select                   4500\n",
      "NaN                      1468\n",
      "online search             808\n",
      "word of mouth             348\n",
      "student of someschool     310\n",
      "other                     186\n",
      "multiple sources          152\n",
      "advertisements             70\n",
      "social media               67\n",
      "email                      26\n",
      "sms                        23\n",
      "Name: Hear, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Specialization\n",
      "############################################\n",
      "select                               1491\n",
      "finance management                    957\n",
      "human resource management             831\n",
      "marketing management                  805\n",
      "NaN                                   699\n",
      "operations management                 492\n",
      "business administration               397\n",
      "it projects management                366\n",
      "supply chain management               348\n",
      "banking, investment and insurance     333\n",
      "travel and tourism                    203\n",
      "media and advertising                 203\n",
      "international business                178\n",
      "healthcare management                 159\n",
      "hospitality management                114\n",
      "e-commerce                            112\n",
      "retail management                     100\n",
      "rural and agribusiness                 73\n",
      "e-business                             57\n",
      "services excellence                    40\n",
      "Name: Specialization, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of City\n",
      "############################################\n",
      "mumbai                         3209\n",
      "select                         1728\n",
      "thane & outskirts               745\n",
      "other cities                    685\n",
      "NaN                             682\n",
      "other cities of maharashtra     455\n",
      "other metro cities              380\n",
      "tier ii cities                   74\n",
      "Name: City, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Page_Views\n",
      "############################################\n",
      "2.00     1795\n",
      "3.00     1196\n",
      "0.00      907\n",
      "4.00      896\n",
      "1.00      651\n",
      "         ... \n",
      "55.00       1\n",
      "1.64        1\n",
      "3.83        1\n",
      "1.63        1\n",
      "8.50        1\n",
      "Name: Page_Views, Length: 115, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Total_Visits\n",
      "############################################\n",
      "2.0      1680\n",
      "3.0      1306\n",
      "4.0      1120\n",
      "0.0       907\n",
      "5.0       783\n",
      "         ... \n",
      "141.0       1\n",
      "54.0        1\n",
      "42.0        1\n",
      "43.0        1\n",
      "41.0        1\n",
      "Name: Total_Visits, Length: 42, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Last_Activity\n",
      "############################################\n",
      "email opened                    3043\n",
      "sms sent                        2426\n",
      "page visited on website          635\n",
      "olark chat conversation          474\n",
      "converted to lead                428\n",
      "email bounced                    303\n",
      "email link clicked               225\n",
      "form submitted on website        116\n",
      "NaN                              103\n",
      "unreachable                       93\n",
      "unsubscribed                      61\n",
      "had a phone conversation          30\n",
      "approached upfront                 9\n",
      "view in browser link clicked       6\n",
      "email marked spam                  2\n",
      "email received                     2\n",
      "resubscribed to emails             1\n",
      "visited booth in tradeshow         1\n",
      "Name: Last_Activity, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Source\n",
      "############################################\n",
      "google               2873\n",
      "direct traffic       2543\n",
      "organic search       1154\n",
      "olark chat            673\n",
      "reference             409\n",
      "referral sites        125\n",
      "welingak website       73\n",
      "facebook               52\n",
      "NaN                    33\n",
      "bing                    6\n",
      "click2call              4\n",
      "live chat               2\n",
      "social media            2\n",
      "press_release           2\n",
      "youtubechannel          1\n",
      "pay per click ads       1\n",
      "blog                    1\n",
      "testone                 1\n",
      "welearn                 1\n",
      "welearnblog_home        1\n",
      "nc_edm                  1\n",
      "Name: Lead_Source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in ['Lead_Profile','Occupation','Hear','Specialization','City','Page_Views','Total_Visits',\n",
    "            'Last_Activity','Lead_Source']:\n",
    "    print('\\n############################################')\n",
    "    print('Unique value distribution of ' + str(col))\n",
    "    print('############################################')\n",
    "    print(df[col].value_counts(dropna=False).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general strategy is employed here to impute nulls, which is to impute them with the 'select' value which is equivalen to null. At a later statge, dummy variables are created and the select dummy variable will be dropped.\n",
    "\n",
    "This will take care of nulls and as well as preserves the information.\n",
    "\n",
    "Same is the case with other columns where the nulls are imputed with 'unspecified' and that dummy variable is dropped later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the above for the strategy\n",
    "\n",
    "df['Specialization'].fillna(value='select', inplace=True)\n",
    "df['Hear'].fillna(value='select', inplace=True)\n",
    "df['Lead_Profile'].fillna(value='select', inplace=True)\n",
    "df['City'].fillna(value='select', inplace=True)\n",
    "\n",
    "# Imputing\n",
    "\n",
    "df['Occupation'].fillna(value='unspecified', inplace=True)\n",
    "df['Last_Activity'].fillna(value='unspecified', inplace=True)\n",
    "df['Lead_Source'].fillna(value='unspecified', inplace=True)\n",
    "\n",
    "# Imputing with the mode value\n",
    "\n",
    "df['Total_Visits'].fillna(value=2.0, inplace=True)\n",
    "df['Page_Views'].fillna(value=2.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Profile\n",
      "############################################\n",
      "select                         5721\n",
      "potential lead                 1508\n",
      "other leads                     484\n",
      "student of someschool           201\n",
      "lateral student                  24\n",
      "dual specialization student      20\n",
      "Name: Lead_Profile, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Occupation\n",
      "############################################\n",
      "unemployed              5150\n",
      "unspecified             1951\n",
      "working professional     638\n",
      "student                  185\n",
      "other                     16\n",
      "housewife                 10\n",
      "businessman                8\n",
      "Name: Occupation, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Hear\n",
      "############################################\n",
      "select                   5968\n",
      "online search             808\n",
      "word of mouth             348\n",
      "student of someschool     310\n",
      "other                     186\n",
      "multiple sources          152\n",
      "advertisements             70\n",
      "social media               67\n",
      "email                      26\n",
      "sms                        23\n",
      "Name: Hear, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Specialization\n",
      "############################################\n",
      "select                               2190\n",
      "finance management                    957\n",
      "human resource management             831\n",
      "marketing management                  805\n",
      "operations management                 492\n",
      "business administration               397\n",
      "it projects management                366\n",
      "supply chain management               348\n",
      "banking, investment and insurance     333\n",
      "travel and tourism                    203\n",
      "media and advertising                 203\n",
      "international business                178\n",
      "healthcare management                 159\n",
      "hospitality management                114\n",
      "e-commerce                            112\n",
      "retail management                     100\n",
      "rural and agribusiness                 73\n",
      "e-business                             57\n",
      "services excellence                    40\n",
      "Name: Specialization, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of City\n",
      "############################################\n",
      "mumbai                         3209\n",
      "select                         2410\n",
      "thane & outskirts               745\n",
      "other cities                    685\n",
      "other cities of maharashtra     455\n",
      "other metro cities              380\n",
      "tier ii cities                   74\n",
      "Name: City, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Page_Views\n",
      "############################################\n",
      "2.00     1932\n",
      "3.00     1196\n",
      "0.00      907\n",
      "4.00      896\n",
      "1.00      651\n",
      "         ... \n",
      "55.00       1\n",
      "1.64        1\n",
      "3.83        1\n",
      "1.93        1\n",
      "8.50        1\n",
      "Name: Page_Views, Length: 114, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Total_Visits\n",
      "############################################\n",
      "2.0      1817\n",
      "3.0      1306\n",
      "4.0      1120\n",
      "0.0       907\n",
      "5.0       783\n",
      "         ... \n",
      "74.0        1\n",
      "251.0       1\n",
      "32.0        1\n",
      "43.0        1\n",
      "30.0        1\n",
      "Name: Total_Visits, Length: 41, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Last_Activity\n",
      "############################################\n",
      "email opened                    3043\n",
      "sms sent                        2426\n",
      "page visited on website          635\n",
      "olark chat conversation          474\n",
      "converted to lead                428\n",
      "email bounced                    303\n",
      "email link clicked               225\n",
      "form submitted on website        116\n",
      "unspecified                      103\n",
      "unreachable                       93\n",
      "unsubscribed                      61\n",
      "had a phone conversation          30\n",
      "approached upfront                 9\n",
      "view in browser link clicked       6\n",
      "email marked spam                  2\n",
      "email received                     2\n",
      "resubscribed to emails             1\n",
      "visited booth in tradeshow         1\n",
      "Name: Last_Activity, dtype: int64\n",
      "\n",
      "############################################\n",
      "Unique value distribution of Lead_Source\n",
      "############################################\n",
      "google               2873\n",
      "direct traffic       2543\n",
      "organic search       1154\n",
      "olark chat            673\n",
      "reference             409\n",
      "referral sites        125\n",
      "welingak website       73\n",
      "facebook               52\n",
      "unspecified            33\n",
      "bing                    6\n",
      "click2call              4\n",
      "live chat               2\n",
      "social media            2\n",
      "press_release           2\n",
      "youtubechannel          1\n",
      "pay per click ads       1\n",
      "blog                    1\n",
      "testone                 1\n",
      "welearn                 1\n",
      "welearnblog_home        1\n",
      "nc_edm                  1\n",
      "Name: Lead_Source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in ['Lead_Profile','Occupation','Hear','Specialization','City','Page_Views','Total_Visits',\n",
    "            'Last_Activity','Lead_Source']:\n",
    "    print('\\n############################################')\n",
    "    print('Unique value distribution of ' + str(col))\n",
    "    print('############################################')\n",
    "    print(df[col].value_counts(dropna=False).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3b09db6156c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munivariate_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0mcat_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"object\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def univariate_categorical(df):\n",
    "        \n",
    "   cat_cols = [cname for cname in df.columns if df[cname].dtype == \"object\"]        \n",
    "\n",
    "   for col in cat_cols:\n",
    "        len_cat = len(df[col].unique())\n",
    "        print('\\n############' + col + '############')\n",
    "        print('\\nNumber of unique values => ' + str(len_cat) + '\\n\\n')\n",
    "\n",
    "        if len_cat > 10:\n",
    "            plt.figure(figsize=(15, 12))\n",
    "        else:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "\n",
    "        y = \"count\"\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.countplot(df[col])\n",
    "        count_df = df[col].value_counts().rename(y).reset_index().rename(columns={\"index\":col})\n",
    "\n",
    "        y = \"percent(%)\"\n",
    "        percent_df = df[col].value_counts(normalize=True).apply(lambda x: round(x*100, 2)).rename(y).reset_index().rename(columns={\"index\":col})\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.barplot(percent_df[col], percent_df[y], data=percent_df)\n",
    "\n",
    "        plt.show()\n",
    "        print(tabulate(pd.merge(percent_df, count_df, how='inner'), headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_categorical(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    print('\\n############################################')\n",
    "    print('Unique value distribution of ' + str(col))\n",
    "    print('############################################')\n",
    "    print(df[col].value_counts(dropna=False).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 'No_Email' and 'Free_Copy' columns have only two values, we employ binary encoding using map function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to map\n",
    "varlist =  ['No_Email', 'Free_Copy']\n",
    "\n",
    "# Defining the map function\n",
    "def binary_map(x):\n",
    "    return x.map({'yes': 1, \"no\": 0})\n",
    "\n",
    "# Applying the function to the housing list\n",
    "df[varlist] = df[varlist].apply(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['No_Email', 'Free_Copy']:\n",
    "    print('\\n############################################')\n",
    "    print('Unique value distribution of ' + str(col))\n",
    "    print('############################################')\n",
    "    print(df[col].value_counts(dropna=False).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going with plain old dummy variable creation for 'Lead_Origin', 'Last_Notable_Activity' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy variable for some of the categorical variables and dropping the first one.\n",
    "dummy = pd.get_dummies(df[['Lead_Origin', 'Last_Notable_Activity']], drop_first=True)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created dummies for the below variables, so we can drop them\n",
    "\n",
    "df = df.drop(['Lead_Origin', 'Last_Notable_Activity'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for the remaining categorical variables and dropping the level which was created to impute nulls\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Creating dummy variables for the variable 'Specialization'\n",
    "specialization = pd.get_dummies(df['Specialization'], prefix='Specialization')\n",
    "\n",
    "# Dropping Specialization_select column\n",
    "specialization = specialization.drop(['Specialization_select'], 1)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, specialization], axis=1)\n",
    "\n",
    "# Dropping the redundant column\n",
    "df = df.drop(['Specialization'], 1)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Creating dummy variables for the variable 'Hear'\n",
    "hear = pd.get_dummies(df['Hear'], prefix='Hear')\n",
    "\n",
    "# Dropping Hear_select column\n",
    "hear = hear.drop(['Hear_select'], 1)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, hear], axis=1)\n",
    "\n",
    "# Dropping the redundant column\n",
    "df = df.drop(['Hear'], 1)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Creating dummy variables for the variable 'Lead_Profile'\n",
    "lead_profile = pd.get_dummies(df['Lead_Profile'], prefix='Lead_Profile')\n",
    "\n",
    "# Dropping Lead_Profile_select column\n",
    "lead_profile = lead_profile.drop(['Lead_Profile_select'], 1)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, lead_profile], axis=1)\n",
    "\n",
    "# Dropping the redundant column\n",
    "df = df.drop(['Lead_Profile'], 1)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Creating dummy variables for the variable 'City'\n",
    "city = pd.get_dummies(df['City'], prefix='City')\n",
    "\n",
    "# Dropping City_select column\n",
    "city = city.drop(['City_select'], 1)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, city], axis=1)\n",
    "\n",
    "# Dropping the redundant column\n",
    "df = df.drop(['City'], 1)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Creating dummy variables for the variable 'Occupation'\n",
    "occupation = pd.get_dummies(df['Occupation'], prefix='Occupation')\n",
    "\n",
    "# Dropping Occupation_unspecified column\n",
    "occupation = occupation.drop(['Occupation_unspecified'], 1)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, occupation], axis=1)\n",
    "\n",
    "# Dropping the redundant column\n",
    "df = df.drop(['Occupation'], 1)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Creating dummy variables for the variable 'Last_Activity'\n",
    "last_activity = pd.get_dummies(df['Last_Activity'], prefix='Last_Activity')\n",
    "\n",
    "# Dropping Last_Activity_unspecified column\n",
    "last_activity = last_activity.drop(['Last_Activity_unspecified'], 1)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, last_activity], axis=1)\n",
    "\n",
    "# Dropping the redundant column\n",
    "df = df.drop(['Last_Activity'], 1)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Creating dummy variables for the variable 'Lead_Source'\n",
    "lead_source = pd.get_dummies(df['Lead_Source'], prefix='Lead_Source')\n",
    "\n",
    "# Dropping Lead_Source_unspecified column\n",
    "lead_source = lead_source.drop(['Lead_Source_unspecified'], 1)\n",
    "\n",
    "# Adding the results to the master dataframe\n",
    "df = pd.concat([df, lead_source], axis=1)\n",
    "\n",
    "# Dropping the redundant column\n",
    "df = df.drop(['Lead_Source'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally are left with 106 columns to deal with for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_continuos(df):\n",
    "    \n",
    "    numeric_cols = ['Total_Visits','Time_On_Website','Page_Views']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "    \n",
    "        sns.boxplot(df[col])\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate_continuos(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'Total_Visits' and 'Page_Views' have outliers in their data and will be dealt with the common capping method where we assign the 'Q3+1.5*IQR' value to the values greater than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = 'Total_Visits'\n",
    "\n",
    "print('\\nFrequency distribution of unique values => \\n\\n'+ str(df[col].value_counts(dropna=False).sort_index(ascending = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Page_Views'\n",
    "\n",
    "print('\\nFrequency distribution of unique values => \\n\\n'+ str(df[col].value_counts(dropna=False).sort_index(ascending = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_treatment(df, col):\n",
    "\n",
    "    print('#########################')\n",
    "    print(col)\n",
    "    print('#########################')\n",
    "    \n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    print('Q1 is => ' + str(Q1))\n",
    "\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    print('Q3 is => ' + str(Q3))\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    fence_high = Q3+1.5*IQR\n",
    "    print('Fence High is => ' + str(fence_high))\n",
    "    \n",
    "    print('Imputing values greater than ' + str(fence_high) + ' with the same value')\n",
    "\n",
    "    df.loc[(df[col] > fence_high), col] = fence_high\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = outlier_treatment(df, 'Total_Visits')\n",
    "df = outlier_treatment(df, 'Page_Views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Total_Visits'] == 9.5, 'Total_Visits'] = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate_continuos(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the outliers are treated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Total_Visits'\n",
    "\n",
    "print('\\nFrequency distribution of unique values => \\n\\n'+ str(df[col].value_counts(dropna=False).sort_index(ascending = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = 'Page_Views'\n",
    "\n",
    "print('\\nFrequency distribution of unique values => \\n\\n'+ str(df[col].value_counts(dropna=False).sort_index(ascending = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now build 3 models with taking RFE o/p as 15, 10 and 20 each and will evaluate them based on various metrics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 (RFE 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "\n",
    "X = df.drop(['Converted'], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "\n",
    "y = df['Converted']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using standard scaler for the non dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[['Total_Visits','Time_On_Website','Page_Views']] = scaler.fit_transform(X_train[['Total_Visits','Time_On_Website','Page_Views']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['Total_Visits','Time_On_Website','Page_Views']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(df.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is not clear with the heat map, we will let RFE deal with dropping the variables with high collinearity and subsequently using manual elimination based on VIF and p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 15) # Running RFE with 15 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Check for the VIF values of the feature variables\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(res, X_train_sm, y_train):\n",
    "    # Getting the predicted values on the train set\n",
    "\n",
    "    y_train_pred = res.predict(X_train_sm)\n",
    "    y_train_pred = y_train_pred.values.reshape(-1)\n",
    "\n",
    "    y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "    y_train_pred_final['CustID'] = y_train.index\n",
    "\n",
    "    y_train_pred_final['predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Confusion matrix \n",
    "    confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "    print(confusion)\n",
    "\n",
    "    # Let's check the overall accuracy.\n",
    "    print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF values of all the variables are significant. However we have some variables with p values > 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Occupation_housewife' variable since it has high p value of 0.999 and higher VIF compared to other variables with similar p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Occupation_housewife', 1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Lead_Profile_dual specialization student' variable since it has high p value of 0.999 and higher VIF compared to other variables with similar p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Profile_dual specialization student', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Last_Activity_approached upfront' variable since it has high p value of 0.999 and higher VIF compared to other variables with similar p value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Last_Activity_approached upfront', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Last_Notable_Activity_had a phone conversation' variable since it has relatively higher p value compared to the other variables and also to see if the accuracy of the model drops with dropping this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Last_Notable_Activity_had a phone conversation', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Occupation_other' variable since it has relatively higher p value compared to the other variables and also to see if the accuracy of the model drops with dropping this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Occupation_other', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Lead_Source_welingak website' variable since it has relatively higher p value compared to the other variables and also to see if the accuracy of the model drops with dropping this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Source_welingak website', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Lead_Profile_lateral student' variable since it has relatively higher p value compared to the other variables and also to see if the accuracy of the model drops with dropping this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Profile_lateral student', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop 'Last_Notable_Activity_unreachable' variable since it has relatively higher p value compared to the other variables and also to see if the accuracy of the model drops with dropping this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Last_Notable_Activity_unreachable', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Getting the predicted values on the train set\n",
    "\n",
    "    y_train_pred = res.predict(X_train_sm)\n",
    "    y_train_pred = y_train_pred.values.reshape(-1)\n",
    "\n",
    "    y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "    y_train_pred_final['CustID'] = y_train.index\n",
    "\n",
    "    y_train_pred_final['predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Confusion matrix \n",
    "    confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "    print(confusion)\n",
    "\n",
    "    # Let's check the overall accuracy.\n",
    "    print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy of the model on the training set with 0.5 threshold is 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is 0.87 which is decent and the curve is not close to the diagnol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Optimal Cutoff Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** From the plot above, 0.35 is the optimum point to take it as a cutoff probability **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.35 else 0)\n",
    "y_train_pred_final['lead_score'] = y_train_pred_final.Converted_Prob * 100\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte the confusion matrix\n",
    "\n",
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.Converted, y_train_pred_final.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the curve above, 0.42 is the optimum point to take it as a cutoff probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.42 else 0)\n",
    "y_train_pred_final['lead_score'] = y_train_pred_final.Converted_Prob * 100\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion3 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "\n",
    "confusion3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion3[1,1] # true positive \n",
    "TN = confusion3[0,0] # true negatives\n",
    "FP = confusion3[0,1] # false positives\n",
    "FN = confusion3[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['Total_Visits','Time_On_Website','Page_Views']] = scaler.transform(X_test[['Total_Visits','Time_On_Website','Page_Views']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe which is an array\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "\n",
    "y_test_df['CustID'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending y_test_df and y_pred_1\n",
    "\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "\n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "\n",
    "y_pred_final = y_pred_final.reindex_axis(['CustID','Converted','Converted_Prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go with the threshold of 0.42 which yielded better metrics on train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['final_predicted'] = y_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.42 else 0)\n",
    "y_pred_final['lead_score'] = y_pred_final.Converted_Prob * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion4 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted )\n",
    "\n",
    "confusion4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion4[1,1] # true positive \n",
    "TN = confusion4[0,0] # true negatives\n",
    "FP = confusion4[0,1] # false positives\n",
    "FN = confusion4[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "\n",
    "confusion4[1,1]/(confusion4[0,1]+confusion4[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "\n",
    "confusion4[1,1]/(confusion4[1,0]+confusion4[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detail comments and observations on the metrics is provided at the bottom of this notebook and is used for model comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The approach for splitting data, scaling, RFE, model building logic and variable elimination criteria for the coming models is same as the previous one. Hence, not repeating the same**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 (RFE 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "\n",
    "X = df.drop(['Converted'], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "\n",
    "y = df['Converted']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[['Total_Visits','Time_On_Website','Page_Views']] = scaler.fit_transform(X_train[['Total_Visits','Time_On_Website','Page_Views']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 10) # running RFE with 10 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4a5933f709d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Check for the VIF values of the feature variables\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Occupation_housewife', 1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Profile_dual specialization student', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Last_Activity_approached upfront', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # Getting the predicted values on the train set\n",
    "\n",
    "    y_train_pred = res.predict(X_train_sm)\n",
    "    y_train_pred = y_train_pred.values.reshape(-1)\n",
    "\n",
    "    y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "    y_train_pred_final['CustID'] = y_train.index\n",
    "\n",
    "    y_train_pred_final['predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Confusion matrix \n",
    "    confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "    print(confusion)\n",
    "\n",
    "    # Let's check the overall accuracy.\n",
    "    print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy of the model on the training set with 0.5 threshold is 75.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Converted_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is 0.80 which is decent and the curve is not very close to the diagnol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Optimal Cutoff Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the plot above, 0.42 is the optimum point to take it as a cutoff probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.42 else 0)\n",
    "y_train_pred_final['lead_score'] = y_train_pred_final.Converted_Prob * 100\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positives\n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-762351fba198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's see the sensitivity of our logistic regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TP' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and recall tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.Converted, y_train_pred_final.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the plot above, 0.52 is the optimum point to take it as a cutoff probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.52 else 0)\n",
    "y_train_pred_final['lead_score'] = y_train_pred_final.Converted_Prob * 100\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion3 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "\n",
    "confusion3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion3[1,1] # true positives\n",
    "TN = confusion3[0,0] # true negatives\n",
    "FP = confusion3[0,1] # false positives\n",
    "FN = confusion3[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3c8ccbd1c267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pred_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "precision_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['Total_Visits','Time_On_Website','Page_Views']] = scaler.transform(X_test[['Total_Visits','Time_On_Website','Page_Views']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe which is an array\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "\n",
    "y_test_df['CustID'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending y_test_df and y_pred_1\n",
    "\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "\n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "\n",
    "y_pred_final = y_pred_final.reindex_axis(['CustID','Converted','Converted_Prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go with the threshold of 0.52 which yielded better metrics on train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b83df5ca59d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConverted_Prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.52\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConverted_Prob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_final' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_final['final_predicted'] = y_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.52 else 0)\n",
    "y_pred_final['lead_score'] = y_pred_final.Converted_Prob * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion4 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted )\n",
    "\n",
    "confusion4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion4[1,1] # true positive \n",
    "TN = confusion4[0,0] # true negatives\n",
    "FP = confusion4[0,1] # false positives\n",
    "FN = confusion4[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "\n",
    "confusion4[1,1]/(confusion4[0,1]+confusion4[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "\n",
    "confusion4[1,1]/(confusion4[1,0]+confusion4[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detail comments and observations on the metrics is provided at the bottom of this notebook and is used for model comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 (RFE 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "\n",
    "X = df.drop(['Converted'], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting response variable to y\n",
    "\n",
    "y = df['Converted']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2f681078c951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Visits'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Time_On_Website'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Page_Views'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_Visits'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Time_On_Website'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Page_Views'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[['Total_Visits','Time_On_Website','Page_Views']] = scaler.fit_transform(X_train[['Total_Visits','Time_On_Website','Page_Views']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['Total_Visits','Time_On_Website','Page_Views']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b0da54af0ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# running RFE with 20 variables as output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, 20) # running RFE with 20 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Check for the VIF values of the feature variables\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Profile_dual specialization student', 1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Occupation_housewife', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Last_Activity_approached upfront', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Source_facebook', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Last_Notable_Activity_had a phone conversation', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Occupation_other', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Last_Notable_Activity_unreachable', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Source_welingak website', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Profile_lateral student', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logmodel = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res = logmodel.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy(res, X_train_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Getting the predicted values on the train set\n",
    "\n",
    "    y_train_pred = res.predict(X_train_sm)\n",
    "    y_train_pred = y_train_pred.values.reshape(-1)\n",
    "\n",
    "    y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "    y_train_pred_final['CustID'] = y_train.index\n",
    "\n",
    "    y_train_pred_final['predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Confusion matrix \n",
    "    confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "    print(confusion)\n",
    "\n",
    "    # Let's check the overall accuracy.\n",
    "    print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy of the model on the training set with 0.5 threshold is 81%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is 0.89 which is decent and the curve is not close to the diagnol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Optimal Cutoff Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the plot above, 0.35 is the optimum point to take it as a cutoff probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.35 else 0)\n",
    "y_train_pred_final['lead_score'] = y_train_pred_final.Converted_Prob * 100\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.Converted, y_train_pred_final.predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the plot above, 0.42 is the optimum point to take it as a cutoff probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.42 else 0)\n",
    "y_train_pred_final['lead_score'] = y_train_pred_final.Converted_Prob * 100\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion3 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "\n",
    "confusion3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion3[1,1] # true positive \n",
    "TN = confusion3[0,0] # true negatives\n",
    "FP = confusion3[0,1] # false positives\n",
    "FN = confusion3[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['Total_Visits','Time_On_Website','Page_Views']] = scaler.transform(X_test[['Total_Visits','Time_On_Website','Page_Views']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_pred to a dataframe which is an array\n",
    "\n",
    "y_pred_1 = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head\n",
    "\n",
    "y_pred_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting CustID to index\n",
    "\n",
    "y_test_df['CustID'] = y_test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing index for both dataframes to append them side by side \n",
    "\n",
    "y_pred_1.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending y_test_df and y_pred_1\n",
    "\n",
    "y_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "\n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns\n",
    "\n",
    "y_pred_final = y_pred_final.reindex_axis(['CustID','Converted','Converted_Prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the head of y_pred_final\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final['final_predicted'] = y_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.42 else 0)\n",
    "y_pred_final['lead_score'] = y_pred_final.Converted_Prob * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "\n",
    "metrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion4 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted )\n",
    "\n",
    "confusion4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion4[1,1] # true positive \n",
    "TN = confusion4[0,0] # true negatives\n",
    "FP = confusion4[0,1] # false positives\n",
    "FN = confusion4[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "\n",
    "confusion4[1,1]/(confusion4[0,1]+confusion4[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "\n",
    "confusion4[1,1]/(confusion4[1,0]+confusion4[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detail comments and observations on the metrics is provided at the bottom of this notebook and is used for model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"Metrics1.png\",width=1000,height=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Model 1**\n",
    "\n",
    "AUC is decent, variables are not many and are easily interpretable. Accuracy, Sensitivity, Precision values are comparable with Model 3.\n",
    "\n",
    "Precision ~ 80% which is the target set by CEO.\n",
    "\n",
    "**Model 2**\n",
    "\n",
    "AUC is less compared to Model 1 and 3, variables are not many and are easily interpretable. But, the accuracy and sensitivity values are significantly less than Model 1 and 3.\n",
    "\n",
    "Precision ~ 80% which is the target set by CEO.\n",
    "\n",
    "**Model 3**\n",
    "\n",
    "AUC is good and comparable to Model 1, variables count is high compared to Model 1 and 2. Accuracy, Sensitivity, Precision values are comparable with Model 1.\n",
    "\n",
    "Precision ~ 80% which is the target set by CEO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Verdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model 1 is the winner since it is simple with lesser number of variables, decent AUC and evaluation metrics with precision ~ 80%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
